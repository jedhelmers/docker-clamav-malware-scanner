#!/bin/bash

# Copyright 2021 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License  at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Log commands, and exit on error.
set -x -o errexit

# Check for clam updates on container startup
apt-get update  && apt-get install clamav-daemon -y

# Get latest definitions
freshclam

# Set Clam config file values
# see clamd.conf documentation:
# https://manpages.debian.org/bullseye/clamav-daemon/clamd.conf.5.en.html

# Note: clamav takes the _first_ config value found in the file, so first
# remove any existing values, then append the new values.
grep -vE "^(StreamMaxLength|MaxScanSize|MaxFileSize|MaxRecursion|MaxFiles)" /etc/clamav/clamd.conf  > /etc/clamav/clamd.conf.new
cat >> /etc/clamav/clamd.conf.new << EOF
# It should be MaxFileSize * 1.1. The idea is to scan a chunked out stream of the file two times:
#   First pass -> chunks at MaxFileSize
#   Second pass -> chunks at StreamMaxLength
# In a nutshell, the two-scan system creates a data overlap like laid bricks. This helps to ensure malicious code is not missed in any single
# stream chunk pass.
StreamMaxLength 550M

# Sets the maximum amount of data to be scanned for each input file.
# Archives and other containers are recursively extracted and scanned up to this value.
MaxScanSize 500M

# Files larger than this limit won't be scanned.
# Just kidding. MaxFileSize is now the point when the server logic  begins chunking the readStream. This is the logic
# that allows for scanning files larger than 4GiB.
# Affects the input file itself as well as files contained inside it (when the input file is an archive, a document or some other kind of container).
MaxFileSize 500M

# Nested archives are scanned recursively, e.g. if a Zip archive contains a RAR file, all files within it will also be scanned.
# This options specifies how deeply the process should be continued.
MaxRecursion 16

# Number of files to be scanned within an archive, a document, or any other kind of container.
MaxFiles 10000
EOF
mv -f /etc/clamav/clamd.conf.new /etc/clamav/clamd.conf

# Report options to log
clamconf

# Restart Services
service clamav-daemon force-reload
service clamav-freshclam force-reload

# Run node server process
npm start
